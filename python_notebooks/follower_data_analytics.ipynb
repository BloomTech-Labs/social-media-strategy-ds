{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required base libraries\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Importing required NLP libraries\n",
    "import gensim\n",
    "import spacy\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim import corpora\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from spacy.tokenizer import Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>hours</th>\n",
       "      <th>mins</th>\n",
       "      <th>secs</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>How to UNPIVOT multiple columns into tidy pair...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Shortest Path Algorithms, Part 2: Floyd�Warsha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Code to run SQL queries 10 times faster than B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>New to Data Visualization? Start with New York...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>47</td>\n",
       "      <td>I wrote a Colab notebook that introduces diffe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  hours  mins  secs  \\\n",
       "0           0     16    30    36   \n",
       "1           1     16     0     4   \n",
       "2           2     15     8     1   \n",
       "3           3     14    41    43   \n",
       "4           4      4    57    47   \n",
       "\n",
       "                                                text  \n",
       "0  How to UNPIVOT multiple columns into tidy pair...  \n",
       "1  Shortest Path Algorithms, Part 2: Floyd�Warsha...  \n",
       "2  Code to run SQL queries 10 times faster than B...  \n",
       "3  New to Data Visualization? Start with New York...  \n",
       "4  I wrote a Colab notebook that introduces diffe...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and check datasets format\n",
    "df = pd.read_csv('get_follower_data.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the text column (striping html with white space)\n",
    "df['text'] = df['text'].apply(lambda x: x[0:-1].replace('\\n\\n', ' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to clean texts from emojies\n",
    "def clear_emoji(text):\n",
    "    '''\n",
    "    Extracting emojies from texts\n",
    "    '''\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "            u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# Applying the function to text column in the dataset\n",
    "df['text'] = df['text'].apply(clear_emoji)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Spacy's large dictionary to extract the most important models\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = Tokenizer(nlp.vocab)\n",
    "\n",
    "# Defining extra stop words\n",
    "STOP_WORDS = nlp.Defaults.stop_words.union([\n",
    "    '&amp;', \"don't\", \"i'm\", \"i've\", \"it’s\", \"&gt;\", \"i’m\", 'de',\n",
    "    'la', 'que', 'un', '=', 'con', 'y', 'like', \"you're\", 'en', 'el',\n",
    "    'thank', '+', \"don’t\", \"it's\", \"⦁\", \"we're\", 'd…', 'los', 'fucking',\n",
    "    'para', 'del', \"here's\", \"can't\", \"aren’t\"\n",
    "])\n",
    "\n",
    "# Tokenizing the tweets\n",
    "tokens = []\n",
    "\n",
    "for doc in tokenizer.pipe(df['text'], batch_size=500):\n",
    "    \"\"\"\n",
    "    Update those tokens w/o stopwords\n",
    "    \"\"\"\n",
    "\n",
    "    doc_tokens = []\n",
    "\n",
    "    for token in doc:\n",
    "        if (token.text.lower() not in STOP_WORDS)\n",
    "        & (token.is_punct == False)\n",
    "        & (token.is_space == False):\n",
    "            doc_tokens.append(token.text.lower())\n",
    "\n",
    "    tokens.append(doc_tokens)\n",
    "\n",
    "df['tokens'] = tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting rid of noise, keeping the most useful words\n",
    "id2word = corpora.Dictionary(df['tokens'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a corpus of words to preform the topic modeling \n",
    "corpus = [id2word.doc2bow(text) for text in df['tokens']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'LdaMulticore' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9b30e2e16c59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Initiate topic modeling model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m lda = LdaMulticore(corpus=corpus,\n\u001b[0m\u001b[1;32m      3\u001b[0m                    \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m723812\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                    \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LdaMulticore' is not defined"
     ]
    }
   ],
   "source": [
    "# Initiate topic modeling model\n",
    "lda = LdaMulticore(corpus=corpus,\n",
    "                   id2word=id2word,\n",
    "                   random_state=723812,\n",
    "                   num_topics=15,\n",
    "                   passes=10,\n",
    "                   workers=8)\n",
    "\n",
    "lda.print_topics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clearing the formating to show words\n",
    "words = [re.findall(r'\"([^\"]*)\"',t[1]) for t in lda.print_topics()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter number of the topics\n",
    "topics = [' '.join(t[0:5]) for t in words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Topic 0 ------\n",
      "new good data learn learning\n",
      "\n",
      "------ Topic 1 ------\n",
      "data today new years going\n",
      "\n",
      "------ Topic 2 ------\n",
      "people new data free great\n",
      "\n",
      "------ Topic 3 ------\n",
      "need data #ai new use\n",
      "\n",
      "------ Topic 4 ------\n",
      "day place world r learning\n",
      "\n",
      "------ Topic 5 ------\n",
      "love ibm | new good\n",
      "\n",
      "------ Topic 6 ------\n",
      "new need covid-19 want learning\n",
      "\n",
      "------ Topic 7 ------\n",
      "new data use want great\n",
      "\n",
      "------ Topic 8 ------\n",
      "new work data people thanks\n",
      "\n",
      "------ Topic 9 ------\n",
      "people think know new time\n",
      "\n",
      "------ Topic 10 ------\n",
      "love code people day heard\n",
      "\n",
      "------ Topic 11 ------\n",
      "best great way i’ve new\n",
      "\n",
      "------ Topic 12 ------\n",
      "game working days people coronavirus\n",
      "\n",
      "------ Topic 13 ------\n",
      "time learning #ai data people\n",
      "\n",
      "------ Topic 14 ------\n",
      "people data know time ⠀\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the topics\n",
    "for id, t in enumerate(topics):\n",
    "    print(f\"------ Topic {id} ------\")\n",
    "    print(t, end=\"\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "U4-S1-NLP",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}