{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a regressor on a set of embeddings of tweet texts\n",
    "\n",
    "Use **GetOldTweets3** library (available via Pypi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: GetOldTweets3 in /home/gt/anaconda3/lib/python3.7/site-packages (0.0.11)\n",
      "Requirement already satisfied: pyquery>=1.2.10 in /home/gt/anaconda3/lib/python3.7/site-packages (from GetOldTweets3) (1.4.1)\n",
      "Requirement already satisfied: lxml>=3.5.0 in /home/gt/anaconda3/lib/python3.7/site-packages (from GetOldTweets3) (4.5.0)\n",
      "Requirement already satisfied: cssselect>0.7.9 in /home/gt/anaconda3/lib/python3.7/site-packages (from pyquery>=1.2.10->GetOldTweets3) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install GetOldTweets3\n",
    "import GetOldTweets3 as got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install basilica # might have to install, if not available in underlying environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import json\n",
    "import numpy as np\n",
    "import sklearn.linear_model\n",
    "import sklearn.preprocessing\n",
    "import sklearn.decomposition\n",
    "import basilica\n",
    "import pickle\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_user_name = 'LambdaSchool'\n",
    "count = 100 # during testing\n",
    "API_KEY =  'get from local or env'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_to_dict(twt):\n",
    "    \"\"\"Munges a twt object into a dict, using names of attributes of\n",
    "    object as keys in dict.\n",
    "    'favorites' is a count of 'likes'\n",
    "    'hashtags' is a string that is a space-separated series of hashtags\n",
    "    'mentions' is a string that is a space-separated series of ats (@s)\n",
    "    'urls' is a string that is a space-separated series of URLs\n",
    "    \"\"\"\n",
    "    return {'date' : twt.date\n",
    "            , 'favorites' : twt.favorites\n",
    "            , 'formatted_date' : twt.formatted_date\n",
    "            , 'geo' : twt.geo\n",
    "            , 'hashtags' : twt.hashtags\n",
    "            , 'id' : twt.id\n",
    "            , 'mentions' : twt.mentions\n",
    "            , 'permalink' : twt.permalink\n",
    "            , 'replies' : twt.replies\n",
    "            , 'retweets' : twt.retweets\n",
    "            , 'text' : twt.text\n",
    "            , 'to' : twt.to\n",
    "            , 'urls' : twt.urls\n",
    "            , 'username' : twt.username}   \n",
    "\n",
    "def munge_date(dt):\n",
    "    \"\"\"Munges a datetime.datetime object into a dict, using names of attributes of\n",
    "    object as keys in dict.\n",
    "    'day_of_week' is [0-7] with 0 being 'Monday'\n",
    "    'minute_of_day' is count of minutes from midnight\"\"\"\n",
    "    return {'year' : dt.year \n",
    "            , 'month' : dt.month\n",
    "            , 'day' : dt.day\n",
    "            , 'day_of_week' : dt.weekday()\n",
    "            , 'hour' : dt.hour\n",
    "            , 'minute' : dt.minute\n",
    "            , 'minute_of_day' : (60 * dt.hour) + dt.minute}\n",
    "\n",
    "\n",
    "def join_dicts(got_tweet_object):\n",
    "    \"\"\"Returns a dict that is the result of joining \n",
    "    - a dict that is the result of parsing a GOT object\n",
    "      to  dict, and\n",
    "    - a dict that is the result of munging the a datetime.date\n",
    "      into a dict.\"\"\"\n",
    "    return {**tweet_to_dict(got_tweet_object), **munge_date(got_tweet_object.date)}\n",
    "\n",
    "def munge_tweet_objects(tweet_objects):\n",
    "    return list(map(join_dicts, tweet_objects))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving tweets via GOT3\n",
      "retrieving embeddings via basilica\n",
      "Retrieved 100 embeddings.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['favorites', 'mentions', 'day_of_week', 'minute_of_day'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a set of tweets\n",
    "pickled_fn = './r_tweets.pickle'\n",
    "pickled_path = Path(pickled_fn)\n",
    "\n",
    "# if a pickled file already exists, unpickle it\n",
    "if pickled_path.is_file():\n",
    "    merged_df = pd.read_pickle(pickled_fn)\n",
    "\n",
    "# if a pickled file does not exist yet, get data then pickle it\n",
    "else:  \n",
    "    #  Create object to execute queries\n",
    "    querySpecs = got.manager.TweetCriteria().setUsername(twitter_user_name).setMaxTweets(count)\n",
    "   \n",
    "    print('Retrieving tweets via GOT3')\n",
    "    # retrieve tweets\n",
    "    retrieved_tweets = got.manager.TweetManager.getTweets(querySpecs)\n",
    "    \n",
    "    tweet_dicts = munge_tweet_objects(retrieved_tweets)\n",
    "    \n",
    "#     y_retweets = pd.DataFrame.from_records(tweet_dicts,  columns=['retweets'])\n",
    "#     y_retweets = y_retweets.fillna(0)\n",
    "\n",
    "    y_likes = pd.DataFrame.from_records(tweet_dicts,  columns=['likes'])\n",
    "    y_likes = y_likes.fillna(0)\n",
    "    \n",
    "    columns_not_needed = ['id', 'hashtags', 'replies', 'retweets', 'text', 'favorites', 'mentions',\n",
    "       'to', 'urls', 'year', 'month', 'day', 'date', 'formatted_date', 'permalink', 'username', 'hour', 'minute', 'geo']\n",
    "    times_df = pd.DataFrame.from_records(tweet_dicts,  exclude=columns_not_needed)\n",
    "\n",
    "    # create a df of embeddings of the texts\n",
    "    tweet_texts = [tweet.text for tweet in retrieved_tweets]\n",
    "    print('retrieving embeddings via basilica')\n",
    "    with basilica.Connection(API_KEY) as c:\n",
    "        embeddings = list(c.embed_sentences(tweet_texts))\n",
    "    \n",
    "    print(\"Retrieved \" + str(len(embeddings)) + \" embeddings.\")\n",
    "    normalized_embeddings = sklearn.preprocessing.normalize(embeddings)\n",
    "    colnames = ['embed_col' + str(i) for i in range(len(embeddings[0]))]\n",
    "    normalized_embeddings_df = pd.DataFrame(normalized_embeddings, columns=colnames)  \n",
    "    \n",
    "    merged_df     =     pd.merge(times_df, normalized_embeddings_df, right_index=True, left_index=True)\n",
    "\n",
    "    # pickle the df\n",
    "    merged_df.to_pickle(pickled_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embed_col0</th>\n",
       "      <th>embed_col1</th>\n",
       "      <th>embed_col2</th>\n",
       "      <th>embed_col3</th>\n",
       "      <th>embed_col4</th>\n",
       "      <th>embed_col5</th>\n",
       "      <th>embed_col6</th>\n",
       "      <th>embed_col7</th>\n",
       "      <th>embed_col8</th>\n",
       "      <th>embed_col9</th>\n",
       "      <th>...</th>\n",
       "      <th>embed_col758</th>\n",
       "      <th>embed_col759</th>\n",
       "      <th>embed_col760</th>\n",
       "      <th>embed_col761</th>\n",
       "      <th>embed_col762</th>\n",
       "      <th>embed_col763</th>\n",
       "      <th>embed_col764</th>\n",
       "      <th>embed_col765</th>\n",
       "      <th>embed_col766</th>\n",
       "      <th>embed_col767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015931</td>\n",
       "      <td>-0.009591</td>\n",
       "      <td>0.029823</td>\n",
       "      <td>0.010719</td>\n",
       "      <td>-0.038900</td>\n",
       "      <td>-0.038713</td>\n",
       "      <td>0.026972</td>\n",
       "      <td>0.032410</td>\n",
       "      <td>-0.018273</td>\n",
       "      <td>-0.024048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>-0.001712</td>\n",
       "      <td>0.011461</td>\n",
       "      <td>-0.002155</td>\n",
       "      <td>0.015545</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>-0.031647</td>\n",
       "      <td>-0.012895</td>\n",
       "      <td>0.012229</td>\n",
       "      <td>0.031648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035164</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.031583</td>\n",
       "      <td>0.014191</td>\n",
       "      <td>0.009272</td>\n",
       "      <td>-0.049518</td>\n",
       "      <td>0.027813</td>\n",
       "      <td>0.042434</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>-0.030599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>-0.027250</td>\n",
       "      <td>-0.016545</td>\n",
       "      <td>-0.014361</td>\n",
       "      <td>0.017695</td>\n",
       "      <td>0.014158</td>\n",
       "      <td>-0.038322</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.005988</td>\n",
       "      <td>0.040775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027223</td>\n",
       "      <td>-0.003076</td>\n",
       "      <td>0.022185</td>\n",
       "      <td>0.017983</td>\n",
       "      <td>-0.001771</td>\n",
       "      <td>-0.030092</td>\n",
       "      <td>0.004849</td>\n",
       "      <td>0.037733</td>\n",
       "      <td>0.006084</td>\n",
       "      <td>-0.035582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002299</td>\n",
       "      <td>-0.004929</td>\n",
       "      <td>-0.005112</td>\n",
       "      <td>-0.022495</td>\n",
       "      <td>0.012315</td>\n",
       "      <td>-0.000232</td>\n",
       "      <td>-0.055358</td>\n",
       "      <td>-0.014222</td>\n",
       "      <td>0.009414</td>\n",
       "      <td>0.032656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.044184</td>\n",
       "      <td>-0.020054</td>\n",
       "      <td>0.046462</td>\n",
       "      <td>0.018096</td>\n",
       "      <td>0.035194</td>\n",
       "      <td>-0.020867</td>\n",
       "      <td>-0.009356</td>\n",
       "      <td>0.017132</td>\n",
       "      <td>0.005850</td>\n",
       "      <td>-0.016406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>-0.035959</td>\n",
       "      <td>-0.019320</td>\n",
       "      <td>-0.006499</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.008922</td>\n",
       "      <td>-0.023195</td>\n",
       "      <td>0.005795</td>\n",
       "      <td>-0.013351</td>\n",
       "      <td>0.052417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017101</td>\n",
       "      <td>-0.021225</td>\n",
       "      <td>0.032381</td>\n",
       "      <td>0.009887</td>\n",
       "      <td>0.023359</td>\n",
       "      <td>-0.043089</td>\n",
       "      <td>0.006115</td>\n",
       "      <td>0.049163</td>\n",
       "      <td>-0.016186</td>\n",
       "      <td>-0.034511</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002739</td>\n",
       "      <td>-0.010104</td>\n",
       "      <td>-0.018705</td>\n",
       "      <td>-0.023456</td>\n",
       "      <td>0.027306</td>\n",
       "      <td>0.025214</td>\n",
       "      <td>-0.018806</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>0.015818</td>\n",
       "      <td>0.026857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.020511</td>\n",
       "      <td>-0.011412</td>\n",
       "      <td>0.019663</td>\n",
       "      <td>0.031424</td>\n",
       "      <td>-0.009619</td>\n",
       "      <td>-0.045547</td>\n",
       "      <td>0.011763</td>\n",
       "      <td>0.035282</td>\n",
       "      <td>-0.003485</td>\n",
       "      <td>-0.036165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005358</td>\n",
       "      <td>-0.005756</td>\n",
       "      <td>-0.021598</td>\n",
       "      <td>-0.015001</td>\n",
       "      <td>0.020247</td>\n",
       "      <td>0.016553</td>\n",
       "      <td>-0.021384</td>\n",
       "      <td>-0.018000</td>\n",
       "      <td>-0.000585</td>\n",
       "      <td>0.041988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.038468</td>\n",
       "      <td>-0.029616</td>\n",
       "      <td>0.046740</td>\n",
       "      <td>0.030350</td>\n",
       "      <td>0.010551</td>\n",
       "      <td>-0.051023</td>\n",
       "      <td>0.009508</td>\n",
       "      <td>0.035810</td>\n",
       "      <td>0.025113</td>\n",
       "      <td>-0.055883</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008719</td>\n",
       "      <td>-0.006314</td>\n",
       "      <td>-0.027820</td>\n",
       "      <td>-0.023555</td>\n",
       "      <td>0.024306</td>\n",
       "      <td>-0.001848</td>\n",
       "      <td>-0.009763</td>\n",
       "      <td>-0.004845</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.013059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.036078</td>\n",
       "      <td>-0.021617</td>\n",
       "      <td>0.036502</td>\n",
       "      <td>0.025404</td>\n",
       "      <td>0.016809</td>\n",
       "      <td>-0.037948</td>\n",
       "      <td>0.020509</td>\n",
       "      <td>0.006095</td>\n",
       "      <td>-0.000881</td>\n",
       "      <td>-0.045999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>-0.004897</td>\n",
       "      <td>-0.023133</td>\n",
       "      <td>-0.033046</td>\n",
       "      <td>0.025120</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>-0.009817</td>\n",
       "      <td>-0.022853</td>\n",
       "      <td>0.014583</td>\n",
       "      <td>0.013084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.034544</td>\n",
       "      <td>-0.026042</td>\n",
       "      <td>0.009093</td>\n",
       "      <td>0.024633</td>\n",
       "      <td>0.009390</td>\n",
       "      <td>-0.042280</td>\n",
       "      <td>0.032299</td>\n",
       "      <td>0.013476</td>\n",
       "      <td>0.001875</td>\n",
       "      <td>-0.037165</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000254</td>\n",
       "      <td>-0.010017</td>\n",
       "      <td>-0.031978</td>\n",
       "      <td>-0.029655</td>\n",
       "      <td>-0.004985</td>\n",
       "      <td>0.023196</td>\n",
       "      <td>-0.009142</td>\n",
       "      <td>-0.028463</td>\n",
       "      <td>0.009120</td>\n",
       "      <td>0.035746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.040063</td>\n",
       "      <td>-0.032792</td>\n",
       "      <td>0.045650</td>\n",
       "      <td>0.014105</td>\n",
       "      <td>-0.000470</td>\n",
       "      <td>-0.047151</td>\n",
       "      <td>0.020283</td>\n",
       "      <td>-0.003541</td>\n",
       "      <td>0.004260</td>\n",
       "      <td>-0.030289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006287</td>\n",
       "      <td>-0.016042</td>\n",
       "      <td>-0.022327</td>\n",
       "      <td>-0.026471</td>\n",
       "      <td>0.021544</td>\n",
       "      <td>0.014537</td>\n",
       "      <td>-0.005624</td>\n",
       "      <td>-0.011158</td>\n",
       "      <td>0.016574</td>\n",
       "      <td>0.019720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    embed_col0  embed_col1  embed_col2  embed_col3  embed_col4  embed_col5  \\\n",
       "0     0.015931   -0.009591    0.029823    0.010719   -0.038900   -0.038713   \n",
       "1     0.035164    0.002939    0.031583    0.014191    0.009272   -0.049518   \n",
       "2     0.027223   -0.003076    0.022185    0.017983   -0.001771   -0.030092   \n",
       "3     0.044184   -0.020054    0.046462    0.018096    0.035194   -0.020867   \n",
       "4     0.017101   -0.021225    0.032381    0.009887    0.023359   -0.043089   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "95    0.020511   -0.011412    0.019663    0.031424   -0.009619   -0.045547   \n",
       "96    0.038468   -0.029616    0.046740    0.030350    0.010551   -0.051023   \n",
       "97    0.036078   -0.021617    0.036502    0.025404    0.016809   -0.037948   \n",
       "98    0.034544   -0.026042    0.009093    0.024633    0.009390   -0.042280   \n",
       "99    0.040063   -0.032792    0.045650    0.014105   -0.000470   -0.047151   \n",
       "\n",
       "    embed_col6  embed_col7  embed_col8  embed_col9  ...  embed_col758  \\\n",
       "0     0.026972    0.032410   -0.018273   -0.024048  ...      0.002214   \n",
       "1     0.027813    0.042434    0.000494   -0.030599  ...      0.006243   \n",
       "2     0.004849    0.037733    0.006084   -0.035582  ...     -0.002299   \n",
       "3    -0.009356    0.017132    0.005850   -0.016406  ...      0.003304   \n",
       "4     0.006115    0.049163   -0.016186   -0.034511  ...     -0.002739   \n",
       "..         ...         ...         ...         ...  ...           ...   \n",
       "95    0.011763    0.035282   -0.003485   -0.036165  ...      0.005358   \n",
       "96    0.009508    0.035810    0.025113   -0.055883  ...      0.008719   \n",
       "97    0.020509    0.006095   -0.000881   -0.045999  ...      0.001761   \n",
       "98    0.032299    0.013476    0.001875   -0.037165  ...     -0.000254   \n",
       "99    0.020283   -0.003541    0.004260   -0.030289  ...      0.006287   \n",
       "\n",
       "    embed_col759  embed_col760  embed_col761  embed_col762  embed_col763  \\\n",
       "0      -0.001712      0.011461     -0.002155      0.015545      0.014710   \n",
       "1      -0.027250     -0.016545     -0.014361      0.017695      0.014158   \n",
       "2      -0.004929     -0.005112     -0.022495      0.012315     -0.000232   \n",
       "3      -0.035959     -0.019320     -0.006499      0.000992      0.008922   \n",
       "4      -0.010104     -0.018705     -0.023456      0.027306      0.025214   \n",
       "..           ...           ...           ...           ...           ...   \n",
       "95     -0.005756     -0.021598     -0.015001      0.020247      0.016553   \n",
       "96     -0.006314     -0.027820     -0.023555      0.024306     -0.001848   \n",
       "97     -0.004897     -0.023133     -0.033046      0.025120      0.003318   \n",
       "98     -0.010017     -0.031978     -0.029655     -0.004985      0.023196   \n",
       "99     -0.016042     -0.022327     -0.026471      0.021544      0.014537   \n",
       "\n",
       "    embed_col764  embed_col765  embed_col766  embed_col767  \n",
       "0      -0.031647     -0.012895      0.012229      0.031648  \n",
       "1      -0.038322      0.005454      0.005988      0.040775  \n",
       "2      -0.055358     -0.014222      0.009414      0.032656  \n",
       "3      -0.023195      0.005795     -0.013351      0.052417  \n",
       "4      -0.018806      0.001975      0.015818      0.026857  \n",
       "..           ...           ...           ...           ...  \n",
       "95     -0.021384     -0.018000     -0.000585      0.041988  \n",
       "96     -0.009763     -0.004845      0.001076      0.013059  \n",
       "97     -0.009817     -0.022853      0.014583      0.013084  \n",
       "98     -0.009142     -0.028463      0.009120      0.035746  \n",
       "99     -0.005624     -0.011158      0.016574      0.019720  \n",
       "\n",
       "[100 rows x 768 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_likes.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colnames = ['embed_col' + str(i) for i in range(len(embeddings[0]))]\n",
    "\n",
    "# # put the normalized embeddings back in a dataframe\n",
    "# normalized_embeddings_df = pd.DataFrame(normalized_embeddings, columns=colnames)\n",
    "# # PCA the embeddings\n",
    "# # sklearn.get_config()\n",
    "# normalized_embeddings_df.shape\n",
    "\n",
    "# normalized_embeddings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into X matrix (embeddings) and y vector (retweet or like count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_likes = merged_df['favorites']\n",
    "# print(y_likes.shape)\n",
    "# print(y_likes.isna().value_counts())\n",
    "type(merged_df['favorites'].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import sklearn.linear_model\n",
    "# import sklearn.preprocessing\n",
    "# import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_df.values\n",
    "\n",
    "X_train, X_test = sklearn.model_selection.train_test_split(X, random_state=72)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_retweets_train, y_retweets_test = sklearn.model_selection.train_test_split(y_retweets, random_state=72)\n",
    "\n",
    "y_likes_train, y_likes_test = sklearn.model_selection.train_test_split(y_likes, random_state=72)\n",
    "\n",
    "y_likes\n",
    "# X_train\n",
    "# y_retweets\n",
    "# retweets_model = sklearn.linear_model.LogisticRegression(max_iter=100)\n",
    "\n",
    "# print(type(y_likes_train))\n",
    "# print(type(y_likes_train.values))\n",
    "# print(type(y_likes_train.values[0]))\n",
    "# print(type(X_train.values[0]))\n",
    "# y_likes_train = pd.DataFrame(y_likes_train)\n",
    "# _likes_train\n",
    "# X_train\n",
    "# retweets_model.fit(X_train, y_likes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likes_model = sklearn.linear_model.LogisticRegression(max_iter=100)\n",
    "# likes_model.fit(X_train, y_likes_train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Retweets Train accuracy: %.3f' % retweets_model.score(X_train, y_retweets_train))\n",
    "print('Retweets Test accuracy: %.3f' % retweets_model.score(X_test, y_retweets_test))\n",
    "\n",
    "print('Likes Train accuracy: %.3f' % likes_model.score(X_train, y_likes_train))\n",
    "print('Likes Test accuracy: %.3f' % likes_model.score(X_test, y_likes_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_retweets[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_retweets_one_embedding(embdng):\n",
    "    \"\"\"Use model to predict based on one embedding.\"\"\"\n",
    "    return retweets_model.predict(embdng)[0]\n",
    "\n",
    "def predict_retweets_one_by_index(embeddings_array, idx):\n",
    "    \"\"\"Use model to predict based on one embedding,\n",
    "    selected by index from a list of embeddings.\"\"\"\n",
    "    return ('predicted retweets', \n",
    "            predict_retweets_one_embedding(embeddings_array[idx].reshape(1,-1)), \n",
    "            'actual', y_retweets[idx])\n",
    "\n",
    "\n",
    "def predict_likes_one_embedding(embdng):\n",
    "    \"\"\"Use model to predict based on one embedding.\"\"\"\n",
    "    return likes_model.predict(embdng)[0]\n",
    "\n",
    "def predict_likes_one_by_index(embeddings_array, idx):\n",
    "    \"\"\"Use model to predict based on one embedding,\n",
    "    selected by index from a list of embeddings.\"\"\"\n",
    "    return  ('predicted likes', \n",
    "             predict_likes_one_embedding(embeddings_array[idx].reshape(1,-1)),\n",
    "             y_likes[idx])\n",
    "             \n",
    "\n",
    "foo = merged_df.values\n",
    "predict_retweets_one_by_index(foo,5)\n",
    "predict_likes_one_by_index(foo,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
